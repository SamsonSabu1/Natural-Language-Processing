{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ypWlSdXYVLg",
        "outputId": "28df9765-396d-41cf-c633-56a421cc8a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gKuza5nYu1D",
        "outputId": "92cbf1da-aa19-4b4c-aee0-af9318fd1ac8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.append(lemma.name())\n",
        "    return list(set(synonyms))\n"
      ],
      "metadata": {
        "id": "FIq9KJnzYV3d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_word_info(word):\n",
        "    syn_list = get_synonyms(word)\n",
        "\n",
        "    # a) Find the 3rd meaning of the word in the list.\n",
        "    third_meaning = None\n",
        "    if len(wordnet.synsets(word)) >= 3:\n",
        "        third_meaning = wordnet.synsets(word)[2].definition()\n",
        "\n",
        "    # b) Extract the nouns of the word from the synonyms list.\n",
        "    nouns = [lemma.name() for syn in wordnet.synsets(word) for lemma in syn.lemmas() if syn.pos() == 'n']\n",
        "\n",
        "    # c) Extract the verbs of the word from the synonyms list.\n",
        "    verbs = [lemma.name() for syn in wordnet.synsets(word) for lemma in syn.lemmas() if syn.pos() == 'v']\n",
        "\n",
        "    # d) Extract the adjectives of the word from the synonyms list.\n",
        "    adjectives = [lemma.name() for syn in wordnet.synsets(word) for lemma in syn.lemmas() if syn.pos() == 'a']\n",
        "\n",
        "    # e) Extract the adverbs of the word from the synonyms list.\n",
        "    adverbs = [lemma.name() for syn in wordnet.synsets(word) for lemma in syn.lemmas() if syn.pos() == 'r']\n",
        "\n",
        "    # f) Extract the definition of the word.\n",
        "    definition = wordnet.synsets(word)[0].definition() if wordnet.synsets(word) else None\n",
        "\n",
        "    # g) Find the hypernyms of each word.\n",
        "    hypernyms = [syn.hypernyms() for syn in wordnet.synsets(word)]\n",
        "\n",
        "    # h) Find the hyponyms of each word.\n",
        "    hyponyms = [syn.hyponyms() for syn in wordnet.synsets(word)]\n",
        "\n",
        "    # i) Find the similarities of any two hyponyms of a word.\n",
        "    hyponym_pairs_similarity = None\n",
        "    if len(hyponyms) >= 2 and hyponyms[0] and hyponyms[1]:\n",
        "             hyponym_pairs_similarity = hyponyms[0][0].wup_similarity(hyponyms[1][0])\n",
        "\n",
        "    return {\n",
        "        'third_meaning': third_meaning,\n",
        "        'nouns': nouns,\n",
        "        'verbs': verbs,\n",
        "        'adjectives': adjectives,\n",
        "        'adverbs': adverbs,\n",
        "        'definition': definition,\n",
        "        'hypernyms': hypernyms,\n",
        "        'hyponyms': hyponyms,\n",
        "        'hyponym_pairs_similarity': hyponym_pairs_similarity\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0mlQ2lZcYp7L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_search = \"bear\"\n",
        "word_info = get_word_info(word_to_search)\n",
        "print(f\"Word: {word_to_search}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pys9Nhl1ZQzK",
        "outputId": "ecf5c1be-3139-4e34-beae-246a87998b15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: bear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Third Meaning: {word_info['third_meaning']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoqjDptJZUQh",
        "outputId": "8ee99a2e-0382-4b92-ede4-a2b0aa2f50b3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Third Meaning: have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nouns: {word_info['nouns']}\")\n",
        "print(f\"Verbs: {word_info['verbs']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eL3m9ttZZg6",
        "outputId": "33cbf4c9-742f-4c2b-c186-cf1a25bed873"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['bear', 'bear']\n",
            "Verbs: ['bear', 'give_birth', 'deliver', 'bear', 'birth', 'have', 'digest', 'endure', 'stick_out', 'stomach', 'bear', 'stand', 'tolerate', 'support', 'brook', 'abide', 'suffer', 'put_up', 'bear', 'bear', 'turn_out', 'bear', 'take_over', 'accept', 'assume', 'hold', 'bear', 'carry', 'contain', 'yield', 'pay', 'bear', 'wear', 'bear', 'behave', 'acquit', 'bear', 'deport', 'conduct', 'comport', 'carry', 'bear', 'hold', 'hold', 'carry', 'bear', 'have_a_bun_in_the_oven', 'bear', 'carry', 'gestate', 'expect']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Adjectives: {word_info['adjectives']}\")\n",
        "print(f\"Adverbs: {word_info['adverbs']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W1TYnbHZbjI",
        "outputId": "89df409a-f002-49f5-81a2-4bf0c00bdba3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjectives: []\n",
            "Adverbs: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Definition: {word_info['definition']}\")\n",
        "print(f\"Hypernyms: {word_info['hypernyms']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vfb7afoZdYR",
        "outputId": "505988f2-e72b-4133-eb2b-f2bbf45d5164"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition: massive plantigrade carnivorous or omnivorous mammals with long shaggy coats and strong claws\n",
            "Hypernyms: [[Synset('carnivore.n.01')], [Synset('investor.n.01')], [Synset('have.v.02')], [Synset('produce.v.01')], [Synset('permit.v.01')], [Synset('transport.v.02')], [Synset('make.v.03')], [Synset('take.v.08')], [Synset('include.v.01')], [Synset('gain.v.08')], [Synset('have.v.02')], [Synset('act.v.01'), Synset('hold.v.14')], [Synset('have.v.01')], [], [Synset('give_birth.v.01')]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Hyponyms: {word_info['hyponyms']}\")\n",
        "print(f\"Hyponym Pairs Similarity: {word_info['hyponym_pairs_similarity']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwDwvOQMZhcP",
        "outputId": "ab7fc940-279f-4d39-8d7b-a53d5e775f92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyponyms: [[Synset('american_black_bear.n.01'), Synset('asiatic_black_bear.n.01'), Synset('bear_cub.n.01'), Synset('brown_bear.n.01'), Synset('bruin.n.01'), Synset('ice_bear.n.01'), Synset('sloth_bear.n.01')], [], [Synset('carry.v.26')], [Synset('calve.v.02'), Synset('cub.v.01'), Synset('drop.v.23'), Synset('farrow.v.01'), Synset('fawn.v.03'), Synset('foal.v.01'), Synset('have_a_bun_in_the_oven.v.01'), Synset('kitten.v.01'), Synset('lamb.v.01'), Synset('litter.v.03'), Synset('twin.v.04'), Synset('whelp.v.01')], [Synset('accept.v.07'), Synset('bear_up.v.01'), Synset('pay.v.09'), Synset('sit_out.v.02'), Synset('stand_for.v.04'), Synset('take_a_joke.v.01'), Synset('take_lying_down.v.01')], [Synset('frogmarch.v.02')], [Synset('crop.v.03'), Synset('fruit.v.02'), Synset('overbear.v.02'), Synset('seed.v.03'), Synset('spin_off.v.01')], [Synset('face_the_music.v.01')], [Synset('enclose.v.02'), Synset('retain.v.01')], [Synset('net.v.02'), Synset('pay_off.v.01')], [], [Synset('assert.v.03'), Synset('deal.v.08'), Synset('fluster.v.01'), Synset('pose.v.04'), Synset('walk_around.v.03')], [], [Synset('behave.v.02'), Synset('piggyback.v.04'), Synset('poise.v.04'), Synset('sling.v.04'), Synset('stoop.v.05')], []]\n",
            "Hyponym Pairs Similarity: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z5ybvzIcZh67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}